{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "stars = []\n",
    "\n",
    "dates = []\n",
    "\n",
    "countries = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "        \n",
    "    for para in parsed_content.find_all(\"div\", {\"class\", \"rating-10\"}):\n",
    "        try:\n",
    "            stars.append(para.span.text)\n",
    "        except:\n",
    "            print(f\"Error on page {i}\")\n",
    "            stars.append(\"None\")\n",
    "            \n",
    "    for para in parsed_content.find_all(\"time\"):\n",
    "        dates.append(para.text)\n",
    "\n",
    "    for para in parsed_content.find_all(\"h3\"):\n",
    "        countries.append(para.span.next_sibling.text.strip(\"()\"))\n",
    "    \n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1010, 1000, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews), len(stars), len(dates), len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = [stars for star in stars if \"\\t\" not in star]\n",
    "len(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"reviews\": reviews,\n",
    "    \"stars\": stars,\n",
    "    \"dates\": dates,\n",
    "    \"countries\": countries\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>dates</th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  The customer service is one of...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>18th August 2024</td>\n",
       "      <td>(United States)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | Before my flight, I was forced ...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>15th August 2024</td>\n",
       "      <td>(United Kingdom)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |   British Airways at its bes...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>12th August 2024</td>\n",
       "      <td>(United Kingdom)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | An excellent flight! Despite...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>12th August 2024</td>\n",
       "      <td>(Lebanon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified | I recently traveled with Bri...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>11th August 2024</td>\n",
       "      <td>(United States)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>✅ Trip Verified |   My family and I were booke...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>9th August 2024</td>\n",
       "      <td>(United Kingdom)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not Verified |  We had to change from AA to BA...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>8th August 2024</td>\n",
       "      <td>(United States)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>✅ Trip Verified | After paying $6500 for ticke...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>8th August 2024</td>\n",
       "      <td>(United States)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>✅ Trip Verified | An excellent flight on BA Ci...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>7th August 2024</td>\n",
       "      <td>(Lebanon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>✅ Trip Verified |   Crew were amazing and atte...</td>\n",
       "      <td>[\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...</td>\n",
       "      <td>7th August 2024</td>\n",
       "      <td>(United Kingdom)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  Not Verified |  The customer service is one of...   \n",
       "1  Not Verified | Before my flight, I was forced ...   \n",
       "2  ✅ Trip Verified |   British Airways at its bes...   \n",
       "3  ✅ Trip Verified | An excellent flight! Despite...   \n",
       "4  ✅ Trip Verified | I recently traveled with Bri...   \n",
       "5  ✅ Trip Verified |   My family and I were booke...   \n",
       "6  Not Verified |  We had to change from AA to BA...   \n",
       "7  ✅ Trip Verified | After paying $6500 for ticke...   \n",
       "8  ✅ Trip Verified | An excellent flight on BA Ci...   \n",
       "9  ✅ Trip Verified |   Crew were amazing and atte...   \n",
       "\n",
       "                                               stars             dates  \\\n",
       "0  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...  18th August 2024   \n",
       "1  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...  15th August 2024   \n",
       "2  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...  12th August 2024   \n",
       "3  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...  12th August 2024   \n",
       "4  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...  11th August 2024   \n",
       "5  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...   9th August 2024   \n",
       "6  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...   8th August 2024   \n",
       "7  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...   8th August 2024   \n",
       "8  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...   7th August 2024   \n",
       "9  [\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5, 2, 1, 8, 8, 3, 1...   7th August 2024   \n",
       "\n",
       "            countries  \n",
       "0    (United States)   \n",
       "1   (United Kingdom)   \n",
       "2   (United Kingdom)   \n",
       "3          (Lebanon)   \n",
       "4    (United States)   \n",
       "5   (United Kingdom)   \n",
       "6    (United States)   \n",
       "7    (United States)   \n",
       "8          (Lebanon)   \n",
       "9   (United Kingdom)   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
